{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolov3_model_train.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/CpNXHfNVbnSf55E5dl+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmayyb/screw-detector/blob/main/Yolov3_model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov3 Model Train on Nut Dataset"
      ],
      "metadata": {
        "id": "nnIJqbe37Icl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Basic Functions"
      ],
      "metadata": {
        "id": "8o_j4DQ6tjHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from scipy import ndimage\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Nvoipgp3sNyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Choose device\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"GPU is not enabled in this notebook. \\n\"\n",
        "          \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook. \\n\"\n",
        "          \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
        "          \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
        "\n",
        "  return device"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TNp2F1nHsSMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = set_device()"
      ],
      "metadata": {
        "id": "VtSR80ACsU63",
        "outputId": "9363c281-d1cf-421f-c964-f42602634e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is not enabled in this notebook. \n",
            "If you want to enable it, in the menu under `Runtime` -> \n",
            "`Hardware accelerator.` and select `GPU` from the dropdown menu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "def fxn():\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)"
      ],
      "metadata": {
        "id": "7t4gN8RpsWzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "vKtWRvzWsZma",
        "outputId": "6f212666-f462-4910-cbdf-438d5ab5e60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9a9a89271754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 120\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd 'gdrive/My Drive/screw_dataset/unpacked/'"
      ],
      "metadata": {
        "id": "IPMsm_K6sbJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the json file with the annotation metadata\n",
        "with open('mvtec_screws.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(data['images'][0])\n",
        "print(data['annotations'][0])"
      ],
      "metadata": {
        "id": "MyhCz8i-sckB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make a dictionary (imgdict), and attach image metadata by image ID\n",
        "imgdict  = {l['id']:l for l in data['images']}"
      ],
      "metadata": {
        "id": "NUXXZh2Osdz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attach images to imgdict that contains metadata\n",
        "for i in imgdict.values():\n",
        "  i['image'] = io.imread(os.path.join('images', i['file_name']))[:,:,:3]"
      ],
      "metadata": {
        "id": "I7UL3Dkisf2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title set up `annodict` annotation dict\n",
        "\n",
        "# remap annotations to dict by image_id\n",
        "from collections import defaultdict\n",
        "annodict = defaultdict(list)\n",
        "for annotation in data['annotations']:\n",
        "  annodict[annotation['image_id']].append(annotation)\n",
        "\n",
        "# setup list of categories\n",
        "categories = data['categories']\n",
        "ncategories = len(categories)\n",
        "cat_ids = [i['id'] for i in categories]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4E5BM6YZsjqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_names = {7:'nut', 3:'wood screw', 2:'lag wood screw', 8:'bolt',\n",
        "                  6:'black oxide screw', 5:'shiny screw', 4:'short wood screw',\n",
        "                  1:'long lag screw', 9:'large nut', 11:'nut', 10:'nut',\n",
        "                  12:'machine screw', 13:'short machine screw' }"
      ],
      "metadata": {
        "id": "8RlbzO01slVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams, gridspec\n",
        "from matplotlib import patches, transforms as plt_transforms\n",
        "\n",
        "rcParams['figure.figsize'] = [16, 6]\n",
        "rcParams['font.size'] =14\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "metadata": {
        "id": "EVbiwHiysofn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title subimage extractor functions \n",
        "def unpack_bbox(bbox):\n",
        "  #bbox as in the json/COCO data format (centerx, centery, width, height, theta is in radians)\n",
        "\n",
        "  rot_center = np.array((bbox[1], bbox[0])).T\n",
        "  width = bbox[3]\n",
        "  height = bbox[2]\n",
        "  theta = -bbox[4]+np.pi/2 #radians\n",
        "  return rot_center, width, height, theta\n",
        "\n",
        "def extract_subimg_bbox(im, bbox):\n",
        "  return extract_subimg(im, *unpack_bbox(bbox))\n",
        "\n",
        "def extract_subimg(im, rot_center, width, height, theta):\n",
        "  #rotates box\n",
        "  rot_bbox = rotbbox_from_coords(rot_center, width, height, theta)\n",
        "\n",
        "  subimg = im[rot_bbox[0,1]:rot_bbox[1,1],rot_bbox[0,0]:rot_bbox[1,0]]\n",
        "  rotated_im = ndimage.rotate(subimg, np.degrees(theta)+180)\n",
        "  newcenter = (np.array(rotated_im.shape)/2).astype(np.int)\n",
        "  rotated_im = rotated_im[int(newcenter[0]-height/2):int(newcenter[0]+height/2), int(newcenter[1]-width/2):int(newcenter[1]+width/2), :3]  #drop alpha channel, if it's there\n",
        "\n",
        "  return rotated_im\n",
        "\n",
        "\n",
        "def rotcorners_from_coords(rot_center, width, height, theta):\n",
        "  rotation = np.array(( (np.cos(theta), -np.sin(theta)),\n",
        "               (np.sin(theta),  np.cos(theta))))\n",
        "\n",
        "  wvec = np.dot(rotation, (width/2, 0))\n",
        "  hvec = np.dot(rotation, (0, height/2))\n",
        "  \n",
        "  #obtains corner points after rotation\n",
        "  corner_points = rot_center + [wvec+hvec, wvec-hvec, -wvec+hvec, -wvec-hvec]\n",
        "  #                            [tr, br, tl, bl]\n",
        "  \n",
        "  return corner_points\n",
        "\n",
        "def rotbbox_from_coords(rot_center, width, height, theta):\n",
        "  corner_points = rotcorners_from_coords(rot_center, width, height, theta)\n",
        "  rot_bbox = np.array((corner_points.min(0), corner_points.max(0))).astype(np.int)\n",
        "  #constrain inside image\n",
        "  rot_bbox[rot_bbox < 0] = 0\n",
        "\n",
        "  return rot_bbox\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zrS7OJu1svO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dict mapping category id to all subimages, can take some time to run\n",
        "# this dictionary contains categorised sub images\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  fxn()\n",
        "  cat_imgdict = defaultdict(list)\n",
        "  for img_id, image in imgdict.items():\n",
        "    for annotation in annodict[img_id]:\n",
        "      bbox = annotation['bbox']\n",
        "      subimg = extract_subimg_bbox(image['image'], bbox)\n",
        "      cat_imgdict[annotation['category_id']].append(subimg.copy())"
      ],
      "metadata": {
        "id": "B0IwgE5Bs4tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Patches"
      ],
      "metadata": {
        "id": "Z6_99zhPteTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get nut patches\n",
        "use_categories = [7, 10]\n",
        "\n",
        "patch_size = np.array((128,128))\n",
        "num_patches_per_category = 500\n",
        "\n",
        "nut_patches = []\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  fxn()\n",
        "  for img_id, image in imgdict.items():\n",
        "    for annotation in annodict[img_id]:\n",
        "      \n",
        "      if annotation['category_id'] in use_categories:\n",
        "        bbox = annotation['bbox']\n",
        "        rot_center, width, height, theta = unpack_bbox(bbox)\n",
        "        subimg = extract_subimg(image['image'], rot_center, patch_size[0], patch_size[1], 0)\n",
        "        \n",
        "        if all(subimg.shape[:2] == patch_size):\n",
        "          nut_patches.append(subimg)\n",
        "          #plt.figure()\n",
        "          #plt.imshow(subimg)\n",
        "\n",
        "    if len(nut_patches) >= num_patches_per_category:\n",
        "      break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lRdQb-yxtHew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title get random blank patches\n",
        "#Select random blank patches\n",
        "blank_patches = []\n",
        "for i in range(len(nut_patches)):\n",
        "  while True: #until a suitable random patch is found\n",
        "    #choose random image\n",
        "    imgid, imgobj = random.choice(list(imgdict.items()))\n",
        "    im = imgobj['image']\n",
        "    #choose random place at least half a patch size from edges\n",
        "    rand_center = np.random.randint((patch_size//2), np.array(im.shape)[:2] - patch_size//2)\n",
        "    corners = rotcorners_from_coords(rand_center, patch_size[0], patch_size[1], 0)\n",
        "    #check if the random patch intersects with any labeled objects\n",
        "    if not any([Polygon(corners).intersects(Polygon(rotcorners_from_coords(*unpack_bbox(annotation['bbox'])))) for annotation in annodict[imgid]]):\n",
        "      rand_patch = im[rand_center[0]-patch_size[0]//2:rand_center[0]+patch_size[0]//2, rand_center[1]-patch_size[1]//2:rand_center[1]+patch_size[1]//2]\n",
        "      blank_patches.append(rand_patch)\n",
        "      break"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3YMmksBftI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visualize nut and blank patches\n",
        "plt.figure()\n",
        "num_examples = 10\n",
        "gs = gridspec.GridSpec(4, num_examples, wspace=.05)\n",
        "for j in range(2):\n",
        "  for i in range(num_examples):\n",
        "    plt.subplot(gs[j, i])\n",
        "    plt.imshow(nut_patches[i+j*10])\n",
        "for j in range(2):\n",
        "  for i in range(num_examples):\n",
        "    plt.subplot(gs[j+2, i])\n",
        "    plt.imshow(blank_patches[i+j*10])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wKlyrrVttLa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_labels = [1,]*len(nut_patches) + [0,]*len(blank_patches)  #1 if nut\n",
        "all_patches = nut_patches + blank_patches #list concat\n",
        "\n",
        "# randomly shuffle\n",
        "shuffle_idx = np.random.choice(len(patch_labels), len(patch_labels), replace=False)\n",
        "patch_labels = [patch_labels[i] for i in shuffle_idx]\n",
        "all_patches = [all_patches[i] for i in shuffle_idx]\n",
        "\n",
        "# Check shapes are correct\n",
        "# assert all([p.shape == (128,128,3) for p in all_patches])\n",
        "[i for i,p in enumerate(all_patches) if p.shape != (128, 128, 3)]"
      ],
      "metadata": {
        "id": "hAaYodNutPME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "N4BfKG9DtV_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "preprocess = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_frac = .2\n",
        "train_number = int(len(all_patches)*train_frac)\n",
        "# test_nuumber = all_patches.len()-train_number\n",
        "train_patches, train_labels = all_patches[:train_number], patch_labels[:train_number]\n",
        "test_patches, test_labels = all_patches[train_number:], patch_labels[train_number:]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(preprocess(all_patches[0]).permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzDLlQRXtRe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(preprocess(all_patches[100]).permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "bqjkD8SotTN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "JSuS7ETxtp2O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joJJXsT5qhNN"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Images\n",
        "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images"
      ],
      "metadata": {
        "id": "HPRyGPOSquTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "results = model(imgs)\n",
        "\n",
        "# Results\n",
        "results.print()\n",
        "results.save()  # or .show()\n",
        "\n",
        "results.xyxy[0]  # img1 predictions (tensor)"
      ],
      "metadata": {
        "id": "iZ3v7KOmrALi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}